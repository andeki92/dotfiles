name: Zsh Startup Benchmark

on:
  pull_request:

# Add workflow permissions
permissions:
  contents: write
  pull-requests: write
  issues: write

# Reusable workflow for environment setup
jobs:
  benchmark-pr:
    name: Benchmark PR Branch
    runs-on: ubuntu-latest
    outputs:
      pr-median: ${{ steps.extract-values.outputs.pr-median }}
      pr-average: ${{ steps.extract-values.outputs.pr-average }}
    steps:
      - name: Check if relevant files changed
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            zsh:
              - 'config/zsh/**'
              - 'scripts/benchmark.sh'
              - '.github/workflows/benchmark.yml'
      - name: Checkout PR Branch
        if: steps.changes.outputs.zsh == 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0
      - name: Install required packages
        if: steps.changes.outputs.zsh == 'true'
        run: |
          # Use multiple mirrors to be more resilient
          echo "Updating apt sources to use multiple mirrors"
          sudo sed -i 's/azure.archive.ubuntu.com/archive.ubuntu.com/g' /etc/apt/sources.list
          for i in {1..3}; do
            echo "Attempt $i: Running apt-get update"
            if sudo apt-get update; then break; fi
            sleep 5
          done
          for i in {1..3}; do
            echo "Attempt $i: Installing packages"
            if sudo apt-get install -y zsh bc stow time; then
              echo "✅ Package installation successful"
              break
            fi
            sleep 5
          done
          which zsh
          which bc
          which stow
          which time
      - name: Setup home environment
        if: steps.changes.outputs.zsh == 'true'
        run: |
          mkdir -p $HOME/.config $HOME/.local/share $HOME/.cache
          if [ -d "config/zsh" ]; then
            stow -d ./config -t $HOME zsh
            echo "✅ Applied zsh configuration from PR branch"
          else
            echo "⚠️ No zsh configuration found in PR branch"
            exit 1
          fi
      - name: Get PR Title
        if: steps.changes.outputs.zsh == 'true'
        id: pr-info
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { data: pullRequest } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            console.log(`PR Title: ${pullRequest.title}`);
            core.setOutput('title', pullRequest.title);
            return pullRequest.title;
          result-encoding: string
      - name: Run benchmark on PR branch
        if: steps.changes.outputs.zsh == 'true'
        id: benchmark-pr
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_DESCRIPTION: ${{ steps.pr-info.outputs.title }}
        run: |
          echo "Using PR #$PR_NUMBER with description: $PR_DESCRIPTION"
          CI=true ./scripts/benchmark.sh --save
          echo "=== Benchmark MD file contents ==="
          cat docs/benchmarks.md
          echo "=== End of benchmark file ==="
          ./scripts/benchmark.sh > benchmark_output.txt
          cat benchmark_output.txt
          mkdir -p /tmp/pr-results
          cp benchmark_output.txt /tmp/pr-results/
          cp docs/benchmarks.md /tmp/pr-results/
      - name: Extract benchmark values
        if: steps.changes.outputs.zsh == 'true'
        id: extract-values
        run: |
          PR_MEDIAN=$(grep "Median startup time" benchmark_output.txt | awk '{print $4}' | tr -d 's')
          PR_AVERAGE=$(grep "Average startup time" benchmark_output.txt | awk '{print $4}' | tr -d 's')
          echo "PR_MEDIAN=$PR_MEDIAN"
          echo "PR_AVERAGE=$PR_AVERAGE"
          PR_MEDIAN="${PR_MEDIAN:-0.000}"
          PR_AVERAGE="${PR_AVERAGE:-0.000}"
          echo "pr-median=$PR_MEDIAN" >> $GITHUB_OUTPUT
          echo "pr-average=$PR_AVERAGE" >> $GITHUB_OUTPUT
      - name: Commit benchmark results
        if: steps.changes.outputs.zsh == 'true'
        run: |
          git fetch origin ${{ github.event.pull_request.head.ref }}
          if git diff --quiet docs/benchmarks.md; then
            echo "No changes to benchmarks.md, skipping commit"
          else
            echo "Changes detected in benchmarks.md, committing updates"
            git config --local user.email "github-actions[bot]@users.noreply.github.com"
            git config --local user.name "github-actions[bot]"
            git add docs/benchmarks.md
            git commit -m "Update benchmarks.md with PR #${{ github.event.pull_request.number }} results [skip ci]"
            git pull --rebase origin ${{ github.event.pull_request.head.ref }}
            if [ $? -ne 0 ]; then
              echo "⚠️ There were conflicts while rebasing. Manual intervention required."
              exit 1
            fi
            git push --force-with-lease origin HEAD:${{ github.event.pull_request.head.ref }}
            echo "✅ Successfully pushed benchmark update to PR branch"
          fi
      - name: Upload PR benchmark results
        if: steps.changes.outputs.zsh == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: pr-benchmark
          path: |
            /tmp/pr-results
            benchmark_output.txt
            docs/benchmarks.md
      - name: Skip benchmark (not relevant)
        if: steps.changes.outputs.zsh != 'true'
        run: echo "No relevant changes, skipping benchmark."
  
  benchmark-main:
    name: Benchmark Main Branch
    runs-on: ubuntu-latest
    outputs:
      main-median: ${{ steps.extract-values.outputs.main-median }}
      main-average: ${{ steps.extract-values.outputs.main-average }}
    steps:
      - name: Check if relevant files changed
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            zsh:
              - 'config/zsh/**'
              - 'scripts/benchmark.sh'
              - '.github/workflows/benchmark.yml'
      - name: Checkout Main Branch
        if: steps.changes.outputs.zsh == 'true'
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0
      - name: Install required packages
        if: steps.changes.outputs.zsh == 'true'
        run: |
          echo "Updating apt sources to use multiple mirrors"
          sudo sed -i 's/azure.archive.ubuntu.com/archive.ubuntu.com/g' /etc/apt/sources.list
          for i in {1..3}; do
            echo "Attempt $i: Running apt-get update"
            if sudo apt-get update; then break; fi
            sleep 5
          done
          for i in {1..3}; do
            echo "Attempt $i: Installing packages"
            if sudo apt-get install -y zsh bc stow time; then
              echo "✅ Package installation successful"
              break
            fi
            sleep 5
          done
          which zsh
          which bc
          which stow
          which time
      - name: Setup home environment
        if: steps.changes.outputs.zsh == 'true'
        run: |
          mkdir -p $HOME/.config $HOME/.local/share $HOME/.cache
          if [ -d "config/zsh" ]; then
            stow -d ./config -t $HOME zsh
            echo "✅ Applied zsh configuration from main branch"
          else
            echo "⚠️ No zsh configuration found in main branch"
            exit 1
          fi
      - name: Run benchmark on main branch
        if: steps.changes.outputs.zsh == 'true'
        id: benchmark-main
        run: |
          ./scripts/benchmark.sh > main_benchmark_output.txt
          cat main_benchmark_output.txt
          mkdir -p /tmp/main-results
          cp main_benchmark_output.txt /tmp/main-results/
      - name: Extract benchmark values
        if: steps.changes.outputs.zsh == 'true'
        id: extract-values
        run: |
          MAIN_MEDIAN=$(grep "Median startup time" main_benchmark_output.txt | awk '{print $4}' | tr -d 's')
          MAIN_AVERAGE=$(grep "Average startup time" main_benchmark_output.txt | awk '{print $4}' | tr -d 's')
          MAIN_MEDIAN="${MAIN_MEDIAN:-0.000}"
          MAIN_AVERAGE="${MAIN_AVERAGE:-0.000}"
          echo "MAIN_MEDIAN=$MAIN_MEDIAN"
          echo "MAIN_AVERAGE=$MAIN_AVERAGE"
          echo "MAIN_MEDIAN=$MAIN_MEDIAN" > /tmp/main-results/times.txt
          echo "MAIN_AVERAGE=$MAIN_AVERAGE" >> /tmp/main-results/times.txt
          echo "main-median=$MAIN_MEDIAN" >> $GITHUB_OUTPUT
          echo "main-average=$MAIN_AVERAGE" >> $GITHUB_OUTPUT
      - name: Upload Main benchmark results
        if: steps.changes.outputs.zsh == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: main-benchmark
          path: /tmp/main-results
      - name: Skip benchmark (not relevant)
        if: steps.changes.outputs.zsh != 'true'
        run: echo "No relevant changes, skipping benchmark."
  
  compare-results:
    name: Compare Benchmark Results
    needs: [benchmark-pr, benchmark-main]
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout PR Branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
      
      - name: Download PR benchmark results
        uses: actions/download-artifact@v4
        with:
          name: pr-benchmark
          path: /tmp/pr-results
      
      - name: Download Main benchmark results
        uses: actions/download-artifact@v4
        with:
          name: main-benchmark
          path: /tmp/main-results
      
      - name: Compare results
        id: compare
        run: |
          PR_MEDIAN="${{ needs.benchmark-pr.outputs.pr-median }}"
          PR_AVERAGE="${{ needs.benchmark-pr.outputs.pr-average }}"
          MAIN_MEDIAN="${{ needs.benchmark-main.outputs.main-median }}"
          MAIN_AVERAGE="${{ needs.benchmark-main.outputs.main-average }}"
          
          echo "PR_MEDIAN=$PR_MEDIAN"
          echo "PR_AVERAGE=$PR_AVERAGE"
          echo "MAIN_MEDIAN=$MAIN_MEDIAN"
          echo "MAIN_AVERAGE=$MAIN_AVERAGE"
          
          # Calculate difference
          if command -v bc &> /dev/null; then
            MEDIAN_DIFF=$(echo "scale=3; $MAIN_MEDIAN - $PR_MEDIAN" | bc)
            AVERAGE_DIFF=$(echo "scale=3; $MAIN_AVERAGE - $PR_AVERAGE" | bc)
            
            if [[ $(echo "$MEDIAN_DIFF > 0" | bc -l) -eq 1 ]]; then
              MEDIAN_STATUS="faster ✅"
            elif [[ $(echo "$MEDIAN_DIFF < 0" | bc -l) -eq 1 ]]; then
              MEDIAN_DIFF=$(echo "scale=3; $MEDIAN_DIFF * -1" | bc)
              MEDIAN_STATUS="slower ❌"
            else
              MEDIAN_STATUS="unchanged ⚠️"
            fi
            
            if [[ $(echo "$AVERAGE_DIFF > 0" | bc -l) -eq 1 ]]; then
              AVERAGE_STATUS="faster ✅"
            elif [[ $(echo "$AVERAGE_DIFF < 0" | bc -l) -eq 1 ]]; then
              AVERAGE_DIFF=$(echo "scale=3; $AVERAGE_DIFF * -1" | bc)
              AVERAGE_STATUS="slower ❌"
            else
              AVERAGE_STATUS="unchanged ⚠️"
            fi
            
            # Calculate percentage difference for thresholds
            if [[ "$MAIN_MEDIAN" != "0.000" && "$PR_MEDIAN" != "0.000" ]]; then
              # Invert the formula: positive means PR is faster, negative means PR is slower
              # When PR time is lower (faster), the result will be positive
              # When PR time is higher (slower), the result will be negative
              PERCENT_CHANGE=$(echo "scale=1; ($MAIN_MEDIAN - $PR_MEDIAN) / $MAIN_MEDIAN * 100" | bc)
              echo "PERCENT_CHANGE=$PERCENT_CHANGE%"
            else
              PERCENT_CHANGE="0.0"
              echo "Cannot calculate percentage change, using default of $PERCENT_CHANGE%"
            fi
          else
            MEDIAN_DIFF="0.000"
            AVERAGE_DIFF="0.000"
            MEDIAN_STATUS="unknown ⚠️"
            AVERAGE_STATUS="unknown ⚠️"
            PERCENT_CHANGE="0.0"
          fi
          
          echo "MEDIAN_DIFF=$MEDIAN_DIFF"
          echo "AVERAGE_DIFF=$AVERAGE_DIFF"
          echo "MEDIAN_STATUS=$MEDIAN_STATUS"
          echo "AVERAGE_STATUS=$AVERAGE_STATUS"
          echo "PERCENT_CHANGE=$PERCENT_CHANGE"
          
          # Store as outputs
          echo "median-diff=$MEDIAN_DIFF" >> $GITHUB_OUTPUT
          echo "average-diff=$AVERAGE_DIFF" >> $GITHUB_OUTPUT
          echo "median-status=$MEDIAN_STATUS" >> $GITHUB_OUTPUT
          echo "average-status=$AVERAGE_STATUS" >> $GITHUB_OUTPUT
          echo "percent-change=$PERCENT_CHANGE" >> $GITHUB_OUTPUT
      
      - name: Get PR Details
        id: pr-details
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { data: pullRequest } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            
            return {
              title: pullRequest.title,
              number: pullRequest.number
            };
          result-encoding: json
      
      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const prDetails = ${{ steps.pr-details.outputs.result }};
            
            const prMedian = '${{ needs.benchmark-pr.outputs.pr-median }}';
            const prAverage = '${{ needs.benchmark-pr.outputs.pr-average }}';
            const mainMedian = '${{ needs.benchmark-main.outputs.main-median }}';
            const mainAverage = '${{ needs.benchmark-main.outputs.main-average }}';
            const medianDiff = '${{ steps.compare.outputs.median-diff }}';
            const averageDiff = '${{ steps.compare.outputs.average-diff }}';
            const medianStatus = '${{ steps.compare.outputs.median-status }}';
            const averageStatus = '${{ steps.compare.outputs.average-status }}';
            const percentChange = '${{ steps.compare.outputs.percent-change }}';
            
            let historySection = '';
            try {
              // Try different paths to find the benchmark file
              let benchmarkContent = '';
              let benchmarkPath = '';
              
              // Check possible paths
              const possiblePaths = [
                '/tmp/pr-results/docs/benchmarks.md',
                '/tmp/pr-results/benchmarks.md',
                'docs/benchmarks.md'
              ];
              
              for (const path of possiblePaths) {
                try {
                  if (fs.existsSync(path)) {
                    benchmarkContent = fs.readFileSync(path, 'utf8');
                    benchmarkPath = path;
                    console.log(`Found benchmark file at: ${path}`);
                    break;
                  }
                } catch (err) {
                  console.log(`Error checking path ${path}: ${err.message}`);
                }
              }
              
              if (benchmarkContent) {
                const ciSection = benchmarkContent.split('## CI Benchmarks')[1];
                if (ciSection) {
                  historySection = ciSection.split('##')[0].trim();
                } else {
                  historySection = 'No CI benchmark history found in the file.';
                }
              } else {
                historySection = 'Could not locate the benchmark history file.';
              }
            } catch (error) {
              historySection = `Error reading benchmark history: ${error.message}`;
              console.log(`Error details: ${error.stack}`);
            }
            
            // Construct comment text
            let commentText = '## Zsh Startup Benchmark Results\n\n';
            
            if (medianDiff === '0.000') {
              commentText += '⚠️ Could not determine performance difference due to missing or invalid measurements.\n\n';
            } else if (percentChange && parseFloat(percentChange) < -25) {
              // PR is significantly slower (>25%)
              commentText += `⚠️ **Warning**: This PR is ${Math.abs(parseFloat(percentChange))}% slower than the main branch.\n\n`;
            } else if (percentChange && parseFloat(percentChange) > 25) {
              // PR is significantly faster (>25%)
              commentText += `🚀 **Great improvement**: This PR is ${percentChange}% faster than the main branch.\n\n`;
            }
            
            commentText += '### Detailed Results\n\n';
            commentText += '|        | PR | Main | Change |\n';
            commentText += '|--------|-----|------|--------|\n';
            commentText += `| Median | ${prMedian}s | ${mainMedian}s | ${medianDiff}s ${medianStatus} |\n`;
            commentText += `| Average | ${prAverage}s | ${mainAverage}s | ${averageDiff}s ${averageStatus} |\n\n`;
            
            commentText += '#### Benchmark History\n';
            commentText += historySection + '\n\n';
            
            commentText += '> Note: Both configurations were properly installed with stow in clean environments.\n';
            commentText += '> For the most accurate results, run `./scripts/benchmark.sh` locally both before and after your changes.';
            
            github.rest.issues.createComment({
              issue_number: prDetails.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentText
            });
      
      - name: Check performance regression
        if: success()
        run: |
          PERCENT_CHANGE="${{ steps.compare.outputs.percent-change }}"
          
          # Strip % sign if present
          PERCENT_CHANGE="${PERCENT_CHANGE/\%/}"
          
          echo "Performance change: $PERCENT_CHANGE%"
          
          # Fail on significant regressions (>25% slower)
          # Negative percentage means PR is slower than main
          if [[ "$PERCENT_CHANGE" =~ ^- && $(echo "${PERCENT_CHANGE#-} > 25" | bc -l) -eq 1 ]]; then
            echo "::error::Performance regression detected: ${PERCENT_CHANGE#-}% slower than main branch!"
            echo "This exceeds the threshold of 25% regression."
            
            # Exit with error - this will make the GitHub check fail
            # To override, use the GitHub UI to bypass this check if needed
            exit 1
          else
            echo "::notice::Performance check passed! Change: $PERCENT_CHANGE%"
          fi

  alls-green-benchmark:
    if: always()
    needs:
      - benchmark-pr
      - benchmark-main
      - compare-results
    runs-on: ubuntu-latest
    steps:
      - name: Decide whether the needed jobs succeeded or failed
        uses: re-actors/alls-green@release/v1
        with:
          jobs: ${{ toJSON(needs) }}
  
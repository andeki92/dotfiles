name: Benchmark zsh startup time

on:
  pull_request:
    paths:
      - 'config/zsh/**'
      - '.github/workflows/benchmark.yml'
      - 'scripts/benchmark.sh'

# Add workflow permissions
permissions:
  contents: write
  pull-requests: write
  issues: write

# Reusable workflow for environment setup
jobs:
  benchmark:
    name: Benchmark PR branch
    runs-on: ubuntu-latest
    outputs:
      pr-median: ${{ steps.extract-values.outputs.pr-median }}
      pr-average: ${{ steps.extract-values.outputs.pr-average }}
    
    steps:
      - name: Check out PR branch
        uses: actions/checkout@v4
<<<<<<< HEAD
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
    
      - name: Install required packages
        run: |
          # Use multiple mirrors to be more resilient
          echo "Updating apt sources to use multiple mirrors"
          sudo sed -i 's/azure.archive.ubuntu.com/archive.ubuntu.com/g' /etc/apt/sources.list
          
          # Add retry logic for apt operations
          for i in {1..3}; do
            echo "Attempt $i: Running apt-get update"
            if sudo apt-get update; then break; fi
            sleep 5
          done
          
          # Install packages with retry
          for i in {1..3}; do
            echo "Attempt $i: Installing packages"
            if sudo apt-get install -y zsh bc stow time; then
              echo "✅ Package installation successful"
              break
            fi
            sleep 5
          done
          
          # Verify installations
          which zsh
          which bc
          which stow
          which time
      
=======
      
      - name: Install packages
        run: |
          sudo apt-get update
          sudo apt-get install -y zsh time bc
      
>>>>>>> 47aecdc (feat(ci): update docs in PR workflow)
      - name: Set up environment
        run: |
          # Create clean home directory structure for test
          mkdir -p $HOME/.config $HOME/.local/share $HOME/.cache
          
          # Install the dotfiles using stow
          if [ -d "config/zsh" ]; then
            stow -d ./config -t $HOME zsh
            echo "✅ Applied zsh configuration from PR branch"
          else
            echo "⚠️ No zsh configuration found in PR branch"
            exit 1
          fi
      
      - name: Get PR Title
        id: pr-info
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { data: pullRequest } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            
            console.log(`PR Title: ${pullRequest.title}`);
            core.setOutput('title', pullRequest.title);
            return pullRequest.title;
          result-encoding: string
      
      - name: Run benchmark on PR branch
        id: benchmark-pr
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_DESCRIPTION: ${{ steps.pr-info.outputs.title }}
        run: |
          # Use PR title as description
          echo "Using PR #$PR_NUMBER with description: $PR_DESCRIPTION"
          
          # Run benchmark with save option
          CI=true ./scripts/benchmark.sh --save
          
          # Print file contents for debugging
          echo "=== Benchmark MD file contents ==="
          cat docs/benchmarks.md
          echo "=== End of benchmark file ==="
          
          # Extract values directly from script output
          ./scripts/benchmark.sh > benchmark_output.txt
          cat benchmark_output.txt
          
          # Save results to file for artifact
          mkdir -p /tmp/pr-results
          cp benchmark_output.txt /tmp/pr-results/
          cp docs/benchmarks.md /tmp/pr-results/
      
      - name: Extract benchmark values
        id: extract-values
        run: |
          # Extract values from benchmark output
          PR_MEDIAN=$(grep "Median startup time" benchmark_output.txt | awk '{print $4}' | tr -d 's')
          PR_AVERAGE=$(grep "Average startup time" benchmark_output.txt | awk '{print $4}' | tr -d 's')
          
          echo "PR_MEDIAN=$PR_MEDIAN"
          echo "PR_AVERAGE=$PR_AVERAGE"
          
          # Make sure we have values
          PR_MEDIAN="${PR_MEDIAN:-0.000}"
          PR_AVERAGE="${PR_AVERAGE:-0.000}"
          
          # Store as outputs
          echo "pr-median=$PR_MEDIAN" >> $GITHUB_OUTPUT
          echo "pr-average=$PR_AVERAGE" >> $GITHUB_OUTPUT
      
      - name: Store PR benchmark time
        run: |
          mkdir -p artifacts
          cp /tmp/pr_time.txt artifacts/

      - name: Upload PR benchmark
        uses: actions/upload-artifact@v3
        with:
          name: pr-benchmark
          path: |
            /tmp/pr-results
            benchmark_output.txt
            docs/benchmarks.md
            
      - name: Commit benchmark results
        run: |
          # Get the current branch name
          BRANCH_NAME=$(git symbolic-ref --short HEAD)
          echo "Current branch: $BRANCH_NAME"
          
          # Check if there are any changes to commit
          if git diff --quiet docs/benchmarks.md; then
            echo "No changes to benchmark file, skipping commit"
          else
            echo "Changes detected in benchmark file, committing..."
            
            # Configure git with GitHub Actions bot
            git config --local user.email "github-actions[bot]@users.noreply.github.com"
            git config --local user.name "github-actions[bot]"
            
            # Stage only the benchmark file
            git add docs/benchmarks.md
            
            # Commit with meaningful message
            git commit -m "Update benchmarks for PR #${{ github.event.pull_request.number }}" -m "Automated benchmark update from GitHub Actions"
            
            # Push back to the PR branch
            echo "Pushing changes to $BRANCH_NAME"
            git push origin $BRANCH_NAME
            
            echo "✅ Successfully committed and pushed benchmark updates"
          fi
  
  benchmark-main:
    name: Benchmark main branch
    runs-on: ubuntu-latest
    outputs:
      main-median: ${{ steps.extract-values.outputs.main-median }}
      main-average: ${{ steps.extract-values.outputs.main-average }}
    
    steps:
      - name: Check out main branch
        uses: actions/checkout@v4
        with:
          ref: main
      
      - name: Install packages
        run: |
          # Use multiple mirrors to be more resilient
          echo "Updating apt sources to use multiple mirrors"
          sudo sed -i 's/azure.archive.ubuntu.com/archive.ubuntu.com/g' /etc/apt/sources.list
          
          # Add retry logic for apt operations
          for i in {1..3}; do
            echo "Attempt $i: Running apt-get update"
            if sudo apt-get update; then break; fi
            sleep 5
          done
          
          # Install packages with retry
          for i in {1..3}; do
            echo "Attempt $i: Installing packages"
            if sudo apt-get install -y zsh bc stow time; then
              echo "✅ Package installation successful"
              break
            fi
            sleep 5
          done
          
          # Verify installations
          which zsh
          which bc
          which stow
          which time
      
      - name: Set up environment
        run: |
          mkdir -p ~/.config/zsh
      
      - name: Run benchmark
        run: |
          # Run benchmark and save output to file
          ./scripts/benchmark.sh > main_benchmark_output.txt
          cat main_benchmark_output.txt
          
          # Save results to file for artifact
          mkdir -p /tmp/main-results
          cp main_benchmark_output.txt /tmp/main-results/
      
      - name: Extract benchmark values
        id: extract-values
        run: |
          MAIN_MEDIAN=$(grep "Median startup time" main_benchmark_output.txt | awk '{print $4}' | tr -d 's')
          MAIN_AVERAGE=$(grep "Average startup time" main_benchmark_output.txt | awk '{print $4}' | tr -d 's')
          
          # Make sure we have values
          MAIN_MEDIAN="${MAIN_MEDIAN:-0.000}"
          MAIN_AVERAGE="${MAIN_AVERAGE:-0.000}"
          
          echo "MAIN_MEDIAN=$MAIN_MEDIAN"
          echo "MAIN_AVERAGE=$MAIN_AVERAGE"
          
          # Save to file for artifact
          echo "MAIN_MEDIAN=$MAIN_MEDIAN" > /tmp/main-results/times.txt
          echo "MAIN_AVERAGE=$MAIN_AVERAGE" >> /tmp/main-results/times.txt
          
          # Store as outputs
          echo "main-median=$MAIN_MEDIAN" >> $GITHUB_OUTPUT
          echo "main-average=$MAIN_AVERAGE" >> $GITHUB_OUTPUT
      
      - name: Upload Main benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: main-benchmark
          path: /tmp/main-results
  
  compare-results:
    name: Compare Benchmark Results
    needs: [benchmark, benchmark-main]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout PR Branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
      
      - name: Download PR benchmark results
        uses: actions/download-artifact@v4
        with:
          name: pr-benchmark
          path: /tmp/pr-results
      
      - name: Download Main benchmark results
        uses: actions/download-artifact@v4
        with:
          name: main-benchmark
          path: /tmp/main-results
      
      - name: Compare results
        id: compare
        run: |
          PR_MEDIAN="${{ needs.benchmark.outputs.pr-median }}"
          PR_AVERAGE="${{ needs.benchmark.outputs.pr-average }}"
          MAIN_MEDIAN="${{ needs.benchmark-main.outputs.main-median }}"
          MAIN_AVERAGE="${{ needs.benchmark-main.outputs.main-average }}"
          
          echo "PR_MEDIAN=$PR_MEDIAN"
          echo "PR_AVERAGE=$PR_AVERAGE"
          echo "MAIN_MEDIAN=$MAIN_MEDIAN"
          echo "MAIN_AVERAGE=$MAIN_AVERAGE"
          
          # Calculate difference
          if command -v bc &> /dev/null; then
            MEDIAN_DIFF=$(echo "scale=3; $MAIN_MEDIAN - $PR_MEDIAN" | bc)
            AVERAGE_DIFF=$(echo "scale=3; $MAIN_AVERAGE - $PR_AVERAGE" | bc)
            
            if [[ $(echo "$MEDIAN_DIFF > 0" | bc -l) -eq 1 ]]; then
              MEDIAN_STATUS="faster ✅"
            elif [[ $(echo "$MEDIAN_DIFF < 0" | bc -l) -eq 1 ]]; then
              MEDIAN_DIFF=$(echo "scale=3; $MEDIAN_DIFF * -1" | bc)
              MEDIAN_STATUS="slower ❌"
            else
              MEDIAN_STATUS="unchanged ⚠️"
            fi
            
            if [[ $(echo "$AVERAGE_DIFF > 0" | bc -l) -eq 1 ]]; then
              AVERAGE_STATUS="faster ✅"
            elif [[ $(echo "$AVERAGE_DIFF < 0" | bc -l) -eq 1 ]]; then
              AVERAGE_DIFF=$(echo "scale=3; $AVERAGE_DIFF * -1" | bc)
              AVERAGE_STATUS="slower ❌"
            else
              AVERAGE_STATUS="unchanged ⚠️"
            fi
            
            # Calculate percentage difference for thresholds
            if [[ "$MAIN_MEDIAN" != "0.000" && "$PR_MEDIAN" != "0.000" ]]; then
              PERCENT_CHANGE=$(echo "scale=1; ($PR_MEDIAN - $MAIN_MEDIAN) / $MAIN_MEDIAN * 100" | bc)
              echo "PERCENT_CHANGE=$PERCENT_CHANGE%"
            else
              PERCENT_CHANGE="0.0"
              echo "Cannot calculate percentage change, using default of $PERCENT_CHANGE%"
            fi
          else
            MEDIAN_DIFF="0.000"
            AVERAGE_DIFF="0.000"
            MEDIAN_STATUS="unknown ⚠️"
            AVERAGE_STATUS="unknown ⚠️"
            PERCENT_CHANGE="0.0"
          fi
          
          echo "MEDIAN_DIFF=$MEDIAN_DIFF"
          echo "AVERAGE_DIFF=$AVERAGE_DIFF"
          echo "MEDIAN_STATUS=$MEDIAN_STATUS"
          echo "AVERAGE_STATUS=$AVERAGE_STATUS"
          echo "PERCENT_CHANGE=$PERCENT_CHANGE"
          
          # Store as outputs
          echo "median-diff=$MEDIAN_DIFF" >> $GITHUB_OUTPUT
          echo "average-diff=$AVERAGE_DIFF" >> $GITHUB_OUTPUT
          echo "median-status=$MEDIAN_STATUS" >> $GITHUB_OUTPUT
          echo "average-status=$AVERAGE_STATUS" >> $GITHUB_OUTPUT
          echo "percent-change=$PERCENT_CHANGE" >> $GITHUB_OUTPUT
      
      - name: Get PR Details
        id: pr-details
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { data: pullRequest } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            
            return {
              title: pullRequest.title,
              number: pullRequest.number
            };
          result-encoding: json
      
      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const prDetails = ${{ steps.pr-details.outputs.result }};
            
            const prMedian = '${{ needs.benchmark.outputs.pr-median }}';
            const prAverage = '${{ needs.benchmark.outputs.pr-average }}';
            const mainMedian = '${{ needs.benchmark-main.outputs.main-median }}';
            const mainAverage = '${{ needs.benchmark-main.outputs.main-average }}';
            const medianDiff = '${{ steps.compare.outputs.median-diff }}';
            const averageDiff = '${{ steps.compare.outputs.average-diff }}';
            const medianStatus = '${{ steps.compare.outputs.median-status }}';
            const averageStatus = '${{ steps.compare.outputs.average-status }}';
            const percentChange = '${{ steps.compare.outputs.percent-change }}';
            
            let historySection = '';
            try {
              // Try different paths to find the benchmark file
              let benchmarkContent = '';
              let benchmarkPath = '';
              
              // Check possible paths
              const possiblePaths = [
                '/tmp/pr-results/docs/benchmarks.md',
                '/tmp/pr-results/benchmarks.md',
                'docs/benchmarks.md'
              ];
              
              for (const path of possiblePaths) {
                try {
                  if (fs.existsSync(path)) {
                    benchmarkContent = fs.readFileSync(path, 'utf8');
                    benchmarkPath = path;
                    console.log(`Found benchmark file at: ${path}`);
                    break;
                  }
                } catch (err) {
                  console.log(`Error checking path ${path}: ${err.message}`);
                }
              }
              
              if (benchmarkContent) {
                const ciSection = benchmarkContent.split('## CI Benchmarks')[1];
                if (ciSection) {
                  historySection = ciSection.split('##')[0].trim();
                } else {
                  historySection = 'No CI benchmark history found in the file.';
                }
              } else {
                historySection = 'Could not locate the benchmark history file.';
              }
            } catch (error) {
              historySection = `Error reading benchmark history: ${error.message}`;
              console.log(`Error details: ${error.stack}`);
            }
            
            // Construct comment text
            let commentText = '## Zsh Startup Benchmark Results\n\n';
            
            if (medianDiff === '0.000') {
              commentText += '⚠️ Could not determine performance difference due to missing or invalid measurements.\n\n';
            } else if (percentChange && percentChange.startsWith('-') && parseFloat(percentChange) < -25) {
              // PR is significantly slower (>25%)
              commentText += `⚠️ **Warning**: This PR is ${percentChange}% slower than the main branch.\n\n`;
            } else if (percentChange && !percentChange.startsWith('-') && parseFloat(percentChange) > 25) {
              // PR is significantly faster (>25%)
              commentText += `🚀 **Great improvement**: This PR is ${percentChange}% faster than the main branch.\n\n`;
            }
            
            commentText += '### Detailed Results\n\n';
            commentText += '|        | PR | Main | Change |\n';
            commentText += '|--------|-----|------|--------|\n';
            commentText += `| Median | ${prMedian}s | ${mainMedian}s | ${medianDiff}s ${medianStatus} |\n`;
            commentText += `| Average | ${prAverage}s | ${mainAverage}s | ${averageDiff}s ${averageStatus} |\n\n`;
            
            commentText += '#### Benchmark History\n';
            commentText += historySection + '\n\n';
            
            commentText += '> Note: Both configurations were properly installed with stow in clean environments.\n';
            commentText += '> For the most accurate results, run `./scripts/benchmark.sh` locally both before and after your changes.';
            
            github.rest.issues.createComment({
              issue_number: prDetails.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentText
            });
      
      - name: Check performance regression
        if: success()
        run: |
          PERCENT_CHANGE="${{ steps.compare.outputs.percent-change }}"
          
          # Strip % sign if present
          PERCENT_CHANGE="${PERCENT_CHANGE/\%/}"
          
          echo "Performance change: $PERCENT_CHANGE%"
          
          # Fail on significant regressions (>25% slower)
          # Negative percentage means PR is slower than main
          if [[ "$PERCENT_CHANGE" =~ ^- && $(echo "${PERCENT_CHANGE#-} > 25" | bc -l) -eq 1 ]]; then
            echo "::error::Performance regression detected: $PERCENT_CHANGE% slower than main branch!"
            echo "This exceeds the threshold of 25% regression."
            
            # Exit with error - this will make the GitHub check fail
            # To override, use the GitHub UI to bypass this check if needed
            exit 1
          else
            echo "::notice::Performance check passed! Change: $PERCENT_CHANGE%"
          fi
<<<<<<< HEAD
=======
     
>>>>>>> 47aecdc (feat(ci): update docs in PR workflow)
